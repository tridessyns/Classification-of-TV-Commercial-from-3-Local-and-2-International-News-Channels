{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_excel('./train_data_cleaned.xlsx')\n",
    "test_data = pd.read_excel('./test_data_cleaned.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Split Features Into Input and Target Features\n",
    "X_train = train_data['summary']\n",
    "y_train = train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<120000x68801 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2514631 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(X_train)\n",
    "count_vect_transform = count_vect.transform(X_train)\n",
    "count_vect_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_vect.fit(count_vect_transform)\n",
    "X_train_tfid_transform = X_train_tfidf.transform(count_vect_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfid_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['science-technology news' 'business news' 'sports news']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(clf.predict(count_vect.transform(['software watching while you work software that can not only monitor every keystroke and action performed at a pc but also be used as legally binding evidence of wrong-doing has been unveiled.  worries about cyber-crime and sabotage have prompted many employers to consider monitoring employees. the developers behind the system claim it is a break-through in the way data is monitored and stored. but privacy advocates are concerned by the invasive nature of such software.  the system is a joint venture between security firm 3ami and storage specialists bridgehead software. they have joined forces to create a system which can monitor computer activity  store it and retrieve disputed files within minutes. more and more firms are finding themselves in deep water as a result of data misuse. sabotage and data theft are most commonly committed from within an organisation according to the national hi-tech crime unit (nhtcu) a survey conducted on its behalf by nop found evidence that more than 80% of medium and large companies have been victims of some form of cyber-crime. bridgehead software has come up with techniques to prove  to a legal standard  that any stored file on a pc has not been tampered with. ironically the impetus for developing the system came as a result of the freedom of information act  which requires companies to store all data for a certain amount of time.  the storage system has been incorporated into an application developed by security firm 3ami which allows every action on a computer to be logged. potentially it could help employers to follow the trail of stolen files and pinpoint whether they had been emailed to a third party  copied  printed  deleted or saved to cd  floppy disk  memory stick or flash card. other activities the system can monitor include the downloading of pornography  the use of racist or bullying language or the copying of applications for personal use. increasingly organisations that handle sensitive data  such as governments  are using biometric log-ins such as fingerprinting to provide conclusive proof of who was using a particular machine at any given time. privacy advocates are concerned that monitoring at work is not only damaging to employee s privacy but also to the relationship between employers and their staff.  that is not the case   said tim ellsmore  managing director of 3ami.  it is not about replacing dialogue but there are issues that you can talk through but you still need proof   he said.  people need to recognise that you are using a pc as a representative of a company and that employers have a legal requirement to store data   he added.','18 percent of Olympic tickets sold in Japan to be refunded', 'LeBron James could play with his son in the NBA after extending contract with Los Angeles Lakers'])))\n",
    "#hitung akurasi data test\n",
    "# print(\"Accuracy:\", accuracy_score(train_data.label, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9007894736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_test_tf = count_vect.transform(test_data.summary)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test_tf)\n",
    "\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(test_data.label, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          business news       0.87      0.86      0.86      1900\n",
      "science-technology news       0.88      0.88      0.88      1900\n",
      "            sports news       0.95      0.98      0.96      1900\n",
      "             world news       0.91      0.89      0.90      1900\n",
      "\n",
      "               accuracy                           0.90      7600\n",
      "              macro avg       0.90      0.90      0.90      7600\n",
      "           weighted avg       0.90      0.90      0.90      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_data.label, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita dapat mengevaluasi performa model klasifikasi dari segi:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Precision \n",
    "a. Macro Average Precision \n",
    "b. Micro Average Precision \n",
    "c. Weighted Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Average Precision: 0.9004470571761125\n",
      "Micro Average Precision: 0.9007894736842105\n",
      "Weighted Average Precision: 0.9004470571761124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_true = test_data.label\n",
    "y_pred = predicted\n",
    "\n",
    "print(\"Macro Average Precision:\",precision_score(y_true, y_pred, average='macro'))\n",
    "print(\"Micro Average Precision:\",precision_score(y_true, y_pred, average='micro'))\n",
    "print(\"Weighted Average Precision:\",precision_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Recall \n",
    "a. Macro Average Recall b. Micro Average Recall c. Weighted Average Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Average Recall: 0.9007894736842106\n",
      "Micro Average Recall: 0.9007894736842105\n",
      "Weighted Average Recall: 0.9007894736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "y_true = test_data.label\n",
    "y_pred = predicted\n",
    "\n",
    "print(\"Macro Average Recall:\", recall_score(y_true,y_pred, average='macro'))\n",
    "print(\"Micro Average Recall:\", recall_score(y_true,y_pred, average='micro'))\n",
    "print(\"Weighted Average Recall:\", recall_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. F1-Score a. Macro Average F1-Score b. Micro Average F1-Score c. Weighted Average F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Average f1_score: 0.9005477138476727\n",
      "Micro Average f1_score: 0.9007894736842105\n",
      "Weighted Average f1_score: 0.9005477138476726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_true = test_data.label\n",
    "y_pred = predicted\n",
    "\n",
    "print(\"Macro Average f1_score:\", f1_score(y_true,y_pred,average='macro'))\n",
    "print(\"Micro Average f1_score:\", f1_score(y_true,y_pred,average='micro'))\n",
    "print(\"Weighted Average f1_score:\",f1_score(y_true,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Improved Naïve Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "          business news       0.87      0.86      0.86      1900\n",
      "science-technology news       0.88      0.88      0.88      1900\n",
      "            sports news       0.95      0.98      0.96      1900\n",
      "             world news       0.91      0.89      0.90      1900\n",
      "\n",
      "               accuracy                           0.90      7600\n",
      "              macro avg       0.90      0.90      0.90      7600\n",
      "           weighted avg       0.90      0.90      0.90      7600\n",
      "\n",
      "accuracy: 0.9007894736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('vect', CountVectorizer(stop_words='english')), \n",
    "                ('tfidf', TfidfTransformer()), \n",
    "                ('model', MultinomialNB()),])\n",
    "mod = pipe.fit(train_data.summary, train_data.label)\n",
    "                 \n",
    "predict = mod.predict(test_data.summary)\n",
    "\n",
    "print(classification_report(test_data.label, predicted))\n",
    "\n",
    "print(\"accuracy:\", accuracy_score(test_data.label, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hasil pemodelan dengan pipeline memberikan akurasi yang sama dengan model Gaussian Naive Bayes sebelumnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(count_vect,open('count_vect.pkl', 'wb'))\n",
    "pickle.dump(clf, open('clf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
